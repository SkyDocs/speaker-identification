{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.9"
    },
    "colab": {
      "name": "speaker-identification.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZIq18T1gsjjJ",
        "outputId": "342dc2ef-5d89-4876-83fd-1b2c984c2ef5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bkQ1QdtQsmsg",
        "outputId": "0cec582a-5455-47d1-92f7-f822e4ad9176",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!unzip \"/content/drive/My Drive/Data-sets/audio.zip\""
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  /content/drive/My Drive/Data-sets/audio.zip\n",
            "replace __MACOSX/._audio? [y]es, [n]o, [A]ll, [N]one, [r]ename: N\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TbDCQypssf5u"
      },
      "source": [
        "import os\n",
        "import shutil\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from pathlib import Path\n",
        "from IPython.display import display, Audio"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OkDYkzl2sf51"
      },
      "source": [
        "DATASET_ROOT = \"/content/audio\"\n",
        "\n",
        "AUDIO_SUBFOLDER = \"audio\"\n",
        "NOISE_SUBFOLDER = \"noise\"\n",
        "\n",
        "DATASET_AUDIO_PATH = os.path.join(DATASET_ROOT, AUDIO_SUBFOLDER)\n",
        "DATASET_NOISE_PATH = os.path.join(DATASET_ROOT, NOISE_SUBFOLDER)"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AkAd7cJUsf55"
      },
      "source": [
        "VALID_SPLIT = 0.1\n",
        "\n",
        "SHUFFLE_SEED = 43\n",
        "\n",
        "SAMPLING_RATE = 16000\n",
        "\n",
        "SCALE = 0.5\n",
        "\n",
        "BATCH_SIZE = 128\n",
        "\n",
        "EPOCHS = 25"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e-fA06IHsf57"
      },
      "source": [
        "Pre-processing DataSet "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6gtXSfsHsf58"
      },
      "source": [
        "# If folder audio, does not exist, create it, otherwise do nothing\n",
        "if os.path.exists(DATASET_AUDIO_PATH) is False:\n",
        "    os.makedirs(DATASET_AUDIO_PATH)\n",
        "\n",
        "# If folder noise, does not exist, create it, otherwise do nothing\n",
        "if os.path.exists(DATASET_NOISE_PATH) is False:\n",
        "    os.makedirs(DATASET_NOISE_PATH)\n",
        "\n",
        "for folder in os.listdir(DATASET_ROOT):\n",
        "    if os.path.isdir(os.path.join(DATASET_ROOT, folder)):\n",
        "        if folder in [AUDIO_SUBFOLDER, NOISE_SUBFOLDER]:\n",
        "            # If folder is audio or noise, do nothing\n",
        "            continue\n",
        "        elif folder in [\"other\", \"_background_noise_\"]:\n",
        "            # If folder is one of the folders that contains noise samples move it to the noise folder\n",
        "            shutil.move(\n",
        "                os.path.join(DATASET_ROOT, folder),\n",
        "                os.path.join(DATASET_NOISE_PATH, folder),\n",
        "            )\n",
        "        else:\n",
        "            # Otherwise, it should be a speaker folder, then move it to audio folder\n",
        "            shutil.move(\n",
        "                os.path.join(DATASET_ROOT, folder),\n",
        "                os.path.join(DATASET_AUDIO_PATH, folder),\n",
        "            )"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1qctF9Fbsf5-"
      },
      "source": [
        "Noise "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mI7n9dvgsf5_",
        "outputId": "e2205c7a-925b-4f03-b4c4-b2a38dd62eb8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Get the list of all noise files\n",
        "noise_paths = []\n",
        "for subdir in os.listdir(DATASET_NOISE_PATH):\n",
        "    subdir_path = Path(DATASET_NOISE_PATH) / subdir\n",
        "    if os.path.isdir(subdir_path):\n",
        "        noise_paths += [\n",
        "            os.path.join(subdir_path, filepath)\n",
        "            for filepath in os.listdir(subdir_path)\n",
        "            if filepath.endswith(\".wav\")\n",
        "        ]\n",
        "\n",
        "print(\"Found {} files belonging to {} directories\".format(len(noise_paths), len(os.listdir(DATASET_NOISE_PATH))))"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 6 files belonging to 2 directories\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vfNTUveAsf6B",
        "outputId": "672f5a1c-3c39-45e6-db70-73e4ebabde3b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "command = (\n",
        "    \"for dir in `ls -1 \" + DATASET_NOISE_PATH + \"`; do \"\n",
        "    \"for file in `ls -1 \" + DATASET_NOISE_PATH + \"/$dir/*.wav`; do \"\n",
        "    \"sample_rate=`ffprobe -hide_banner -loglevel panic -show_streams \"\n",
        "    \"$file | grep sample_rate | cut -f2 -d=`; \"\n",
        "    \"if [ $sample_rate -ne 16000 ]; then \"\n",
        "    \"ffmpeg -hide_banner -loglevel panic -y \"\n",
        "    \"-i $file -ar 16000 temp.wav; \"\n",
        "    \"mv temp.wav $file; \"\n",
        "    \"fi; done; done\"\n",
        ")\n",
        "os.system(command)\n",
        "\n",
        "# Split noise into chunks of 16,000 steps each\n",
        "def load_noise_sample(path):\n",
        "    sample, sampling_rate = tf.audio.decode_wav(\n",
        "        tf.io.read_file(path), desired_channels=1\n",
        "    )\n",
        "    if sampling_rate == SAMPLING_RATE:\n",
        "        # Number of slices of 16000 each that can be generated from the noise sample\n",
        "        slices = int(sample.shape[0] / SAMPLING_RATE)\n",
        "        sample = tf.split(sample[: slices * SAMPLING_RATE], slices)\n",
        "        return sample\n",
        "    else:\n",
        "        print(\"Sampling rate for {} is incorrect. Ignoring it\".format(path))\n",
        "        return None\n",
        "\n",
        "\n",
        "noises = []\n",
        "for path in noise_paths:\n",
        "    sample = load_noise_sample(path)\n",
        "    if sample:\n",
        "        noises.extend(sample)\n",
        "noises = tf.stack(noises)\n",
        "\n",
        "print(\n",
        "    \"{} noise files were split into {} noise samples where each is {} sec. long\".format(\n",
        "        len(noise_paths), noises.shape[0], noises.shape[1] // SAMPLING_RATE\n",
        "    )\n",
        ")"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "6 noise files were split into 354 noise samples where each is 1 sec. long\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OwAfQPKtsf6D"
      },
      "source": [
        "Data-set Gen"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oo7cOAjwsf6E",
        "outputId": "1d8098b5-4958-4246-d5ca-b97d07a56c07",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "\n",
        "def paths_and_labels_to_dataset(audio_paths, labels):\n",
        "    \"\"\"Constructs a dataset of audios and labels.\"\"\"\n",
        "    path_ds = tf.data.Dataset.from_tensor_slices(audio_paths)\n",
        "    audio_ds = path_ds.map(lambda x: path_to_audio(x))\n",
        "    label_ds = tf.data.Dataset.from_tensor_slices(labels)\n",
        "    return tf.data.Dataset.zip((audio_ds, label_ds))\n",
        "\n",
        "\n",
        "def path_to_audio(path):\n",
        "    \"\"\"Reads and decodes an audio file.\"\"\"\n",
        "    audio = tf.io.read_file(path)\n",
        "    audio, _ = tf.audio.decode_wav(audio, 1, SAMPLING_RATE)\n",
        "    return audio\n",
        "\n",
        "\n",
        "def add_noise(audio, noises=None, scale=0.5):\n",
        "    if noises is not None:\n",
        "        # Create a random tensor of the same size as audio ranging from\n",
        "        # 0 to the number of noise stream samples that we have.\n",
        "        tf_rnd = tf.random.uniform(\n",
        "            (tf.shape(audio)[0],), 0, noises.shape[0], dtype=tf.int32\n",
        "        )\n",
        "        noise = tf.gather(noises, tf_rnd, axis=0)\n",
        "\n",
        "        # Get the amplitude proportion between the audio and the noise\n",
        "        prop = tf.math.reduce_max(audio, axis=1) / tf.math.reduce_max(noise, axis=1)\n",
        "        prop = tf.repeat(tf.expand_dims(prop, axis=1), tf.shape(audio)[1], axis=1)\n",
        "\n",
        "        # Adding the rescaled noise to audio\n",
        "        audio = audio + noise * prop * scale\n",
        "\n",
        "    return audio\n",
        "\n",
        "\n",
        "def audio_to_fft(audio):\n",
        "    # Since tf.signal.fft applies FFT on the innermost dimension,\n",
        "    # we need to squeeze the dimensions and then expand them again\n",
        "    # after FFT\n",
        "    audio = tf.squeeze(audio, axis=-1)\n",
        "    fft = tf.signal.fft(\n",
        "        tf.cast(tf.complex(real=audio, imag=tf.zeros_like(audio)), tf.complex64)\n",
        "    )\n",
        "    fft = tf.expand_dims(fft, axis=-1)\n",
        "\n",
        "    # Return the absolute value of the first half of the FFT\n",
        "    # which represents the positive frequencies\n",
        "    return tf.math.abs(fft[:, : (audio.shape[1]), :])\n",
        "\n",
        "\n",
        "# Get the list of audio file paths along with their corresponding labels\n",
        "\n",
        "class_names = os.listdir(DATASET_AUDIO_PATH)\n",
        "print(\"Our class names: {}\".format(class_names,))\n",
        "\n",
        "audio_paths = []\n",
        "labels = []\n",
        "for label, name in enumerate(class_names):\n",
        "    print(\"Processing speaker {}\".format(name,))\n",
        "    dir_path = Path(DATASET_AUDIO_PATH) / name\n",
        "    speaker_sample_paths = [\n",
        "        os.path.join(dir_path, filepath)\n",
        "        for filepath in os.listdir(dir_path)\n",
        "        if filepath.endswith(\".wav\")\n",
        "    ]\n",
        "    audio_paths += speaker_sample_paths\n",
        "    labels += [label] * len(speaker_sample_paths)\n",
        "\n",
        "print(\n",
        "    \"Found {} files belonging to {} classes.\".format(len(audio_paths), len(class_names))\n",
        ")\n",
        "\n",
        "# Shuffle\n",
        "rng = np.random.RandomState(SHUFFLE_SEED)\n",
        "rng.shuffle(audio_paths)\n",
        "rng = np.random.RandomState(SHUFFLE_SEED)\n",
        "rng.shuffle(labels)\n",
        "\n",
        "# Split into training and validation\n",
        "num_val_samples = int(VALID_SPLIT * len(audio_paths))\n",
        "print(\"Using {} files for training.\".format(len(audio_paths) - num_val_samples))\n",
        "train_audio_paths = audio_paths[:-num_val_samples]\n",
        "train_labels = labels[:-num_val_samples]\n",
        "\n",
        "print(\"Using {} files for validation.\".format(num_val_samples))\n",
        "valid_audio_paths = audio_paths[-num_val_samples:]\n",
        "valid_labels = labels[-num_val_samples:]\n",
        "\n",
        "# Create 2 datasets, one for training and the other for validation\n",
        "train_ds = paths_and_labels_to_dataset(train_audio_paths, train_labels)\n",
        "train_ds = train_ds.shuffle(buffer_size=BATCH_SIZE * 8, seed=SHUFFLE_SEED).batch(\n",
        "    BATCH_SIZE\n",
        ")\n",
        "\n",
        "valid_ds = paths_and_labels_to_dataset(valid_audio_paths, valid_labels)\n",
        "valid_ds = valid_ds.shuffle(buffer_size=32 * 8, seed=SHUFFLE_SEED).batch(32)\n",
        "\n",
        "\n",
        "# Add noise to the training set\n",
        "# train_ds = train_ds.map(\n",
        "#     lambda x, y: (add_noise(x, noises, scale=SCALE), y),\n",
        "#     num_parallel_calls=tf.data.experimental.AUTOTUNE,\n",
        "# )\n",
        "\n",
        "# Transform audio wave to the frequency domain using `audio_to_fft`\n",
        "# train_ds = train_ds.map(\n",
        "#     lambda x, y: (audio_to_fft(x), y), num_parallel_calls=tf.data.experimental.AUTOTUNE\n",
        "# )\n",
        "\n",
        "\n",
        "train_ds = train_ds.prefetch(tf.data.experimental.AUTOTUNE)\n",
        "train_ds = train_ds.map(lambda x, y: (add_noise(x, noises, scale=SCALE), y))\n",
        "print(\"--------\")\n",
        "print(train_ds)\n",
        "\n",
        "# valid_ds = valid_ds.map(\n",
        "#     lambda x, y: (audio_to_fft(x), y), num_parallel_calls=tf.data.experimental.AUTOTUNE\n",
        "# )\n",
        "valid_ds = valid_ds.prefetch(tf.data.experimental.AUTOTUNE)\n",
        "valid_ds = valid_ds.map(lambda x, y: (add_noise(x, noises, scale=SCALE), y))"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Our class names: ['Nelson_Mandela', 'harshit', 'avish']\n",
            "Processing speaker Nelson_Mandela\n",
            "Processing speaker harshit\n",
            "Processing speaker avish\n",
            "Found 1800 files belonging to 3 classes.\n",
            "Using 1620 files for training.\n",
            "Using 180 files for validation.\n",
            "--------\n",
            "<MapDataset shapes: ((None, 16000, 1), (None,)), types: (tf.float32, tf.int32)>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tLUj_QCnsf6I"
      },
      "source": [
        "Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gmi7FL1hsf6I",
        "outputId": "b61f79cb-75ad-47e5-ab34-ff235f8de678",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "def residual_block(x, filters, conv_num=3, activation=\"relu\"):\n",
        "    # Shortcut\n",
        "    s = keras.layers.Conv1D(filters, 1, padding=\"same\")(x)\n",
        "    for i in range(conv_num - 1):\n",
        "        x = keras.layers.Conv1D(filters, 3, padding=\"same\")(x)\n",
        "        x = keras.layers.Activation(activation)(x)\n",
        "    x = keras.layers.Conv1D(filters, 3, padding=\"same\")(x)\n",
        "    x = keras.layers.Add()([x, s])\n",
        "    x = keras.layers.Activation(activation)(x)\n",
        "    return keras.layers.MaxPool1D(pool_size=2, strides=2)(x)\n",
        "\n",
        "\n",
        "def build_model(input_shape, num_classes):\n",
        "    inputs = keras.layers.Input(shape=input_shape, name=\"input\")\n",
        "\n",
        "    x = residual_block(inputs, 16, 2)\n",
        "    x = residual_block(x, 32, 2)\n",
        "    x = residual_block(x, 64, 3)\n",
        "    x = residual_block(x, 128, 3)\n",
        "    x = residual_block(x, 128, 3)\n",
        "\n",
        "    x = keras.layers.AveragePooling1D(pool_size=3, strides=3)(x)\n",
        "    x = keras.layers.Flatten()(x)\n",
        "    x = keras.layers.Dense(256, activation=\"relu\")(x)\n",
        "    x = keras.layers.Dense(128, activation=\"relu\")(x)\n",
        "\n",
        "    outputs = keras.layers.Dense(num_classes, activation=\"softmax\", name=\"output\")(x)\n",
        "\n",
        "    return keras.models.Model(inputs=inputs, outputs=outputs)\n",
        "\n",
        "\n",
        "model = build_model((SAMPLING_RATE, 1), len(class_names))\n",
        "\n",
        "model.summary()\n",
        "\n",
        "# Compile the model using Adam's default learning rate\n",
        "model.compile(\n",
        "    optimizer=\"Adam\", loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\"]\n",
        ")\n",
        "\n",
        "# Add callbacks:\n",
        "# 'EarlyStopping' to stop training when the model is not enhancing anymore\n",
        "# 'ModelCheckPoint' to always keep the model that has the best val_accuracy\n",
        "model_save_filename = \"model.h5\"\n",
        "\n",
        "earlystopping_cb = keras.callbacks.EarlyStopping(patience=10, restore_best_weights=True)\n",
        "mdlcheckpoint_cb = keras.callbacks.ModelCheckpoint(\n",
        "    model_save_filename, monitor=\"val_accuracy\", save_best_only=True\n",
        ")"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"functional_1\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input (InputLayer)              [(None, 16000, 1)]   0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_1 (Conv1D)               (None, 16000, 16)    64          input[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "activation (Activation)         (None, 16000, 16)    0           conv1d_1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_2 (Conv1D)               (None, 16000, 16)    784         activation[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv1d (Conv1D)                 (None, 16000, 16)    32          input[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "add (Add)                       (None, 16000, 16)    0           conv1d_2[0][0]                   \n",
            "                                                                 conv1d[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "activation_1 (Activation)       (None, 16000, 16)    0           add[0][0]                        \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling1d (MaxPooling1D)    (None, 8000, 16)     0           activation_1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_4 (Conv1D)               (None, 8000, 32)     1568        max_pooling1d[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_2 (Activation)       (None, 8000, 32)     0           conv1d_4[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_5 (Conv1D)               (None, 8000, 32)     3104        activation_2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_3 (Conv1D)               (None, 8000, 32)     544         max_pooling1d[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "add_1 (Add)                     (None, 8000, 32)     0           conv1d_5[0][0]                   \n",
            "                                                                 conv1d_3[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_3 (Activation)       (None, 8000, 32)     0           add_1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling1d_1 (MaxPooling1D)  (None, 4000, 32)     0           activation_3[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_7 (Conv1D)               (None, 4000, 64)     6208        max_pooling1d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_4 (Activation)       (None, 4000, 64)     0           conv1d_7[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_8 (Conv1D)               (None, 4000, 64)     12352       activation_4[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "activation_5 (Activation)       (None, 4000, 64)     0           conv1d_8[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_9 (Conv1D)               (None, 4000, 64)     12352       activation_5[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_6 (Conv1D)               (None, 4000, 64)     2112        max_pooling1d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "add_2 (Add)                     (None, 4000, 64)     0           conv1d_9[0][0]                   \n",
            "                                                                 conv1d_6[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_6 (Activation)       (None, 4000, 64)     0           add_2[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling1d_2 (MaxPooling1D)  (None, 2000, 64)     0           activation_6[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_11 (Conv1D)              (None, 2000, 128)    24704       max_pooling1d_2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_7 (Activation)       (None, 2000, 128)    0           conv1d_11[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_12 (Conv1D)              (None, 2000, 128)    49280       activation_7[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "activation_8 (Activation)       (None, 2000, 128)    0           conv1d_12[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_13 (Conv1D)              (None, 2000, 128)    49280       activation_8[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_10 (Conv1D)              (None, 2000, 128)    8320        max_pooling1d_2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "add_3 (Add)                     (None, 2000, 128)    0           conv1d_13[0][0]                  \n",
            "                                                                 conv1d_10[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_9 (Activation)       (None, 2000, 128)    0           add_3[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling1d_3 (MaxPooling1D)  (None, 1000, 128)    0           activation_9[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_15 (Conv1D)              (None, 1000, 128)    49280       max_pooling1d_3[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_10 (Activation)      (None, 1000, 128)    0           conv1d_15[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_16 (Conv1D)              (None, 1000, 128)    49280       activation_10[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_11 (Activation)      (None, 1000, 128)    0           conv1d_16[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_17 (Conv1D)              (None, 1000, 128)    49280       activation_11[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_14 (Conv1D)              (None, 1000, 128)    16512       max_pooling1d_3[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "add_4 (Add)                     (None, 1000, 128)    0           conv1d_17[0][0]                  \n",
            "                                                                 conv1d_14[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_12 (Activation)      (None, 1000, 128)    0           add_4[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling1d_4 (MaxPooling1D)  (None, 500, 128)     0           activation_12[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling1d (AveragePooli (None, 166, 128)     0           max_pooling1d_4[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "flatten (Flatten)               (None, 21248)        0           average_pooling1d[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "dense (Dense)                   (None, 256)          5439744     flatten[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_1 (Dense)                 (None, 128)          32896       dense[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "output (Dense)                  (None, 3)            387         dense_1[0][0]                    \n",
            "==================================================================================================\n",
            "Total params: 5,808,083\n",
            "Trainable params: 5,808,083\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZyJW-mgEsf6M"
      },
      "source": [
        "Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5B2F0OPysf6N",
        "outputId": "96c14374-2a2e-4181-a0a3-544cf3faa055",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "history = model.fit(\n",
        "    train_ds,\n",
        "    epochs=EPOCHS,\n",
        "    validation_data=valid_ds,\n",
        "    callbacks=[earlystopping_cb, mdlcheckpoint_cb],\n",
        ")"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/25\n",
            "13/13 [==============================] - 4s 283ms/step - loss: 0.7069 - accuracy: 0.5895 - val_loss: 0.4037 - val_accuracy: 0.7167\n",
            "Epoch 2/25\n",
            "13/13 [==============================] - 3s 198ms/step - loss: 0.4199 - accuracy: 0.7907 - val_loss: 0.5681 - val_accuracy: 0.7056\n",
            "Epoch 3/25\n",
            "13/13 [==============================] - 3s 219ms/step - loss: 0.3656 - accuracy: 0.8309 - val_loss: 0.3039 - val_accuracy: 0.9278\n",
            "Epoch 4/25\n",
            "13/13 [==============================] - 3s 219ms/step - loss: 0.2528 - accuracy: 0.9080 - val_loss: 0.1304 - val_accuracy: 0.9333\n",
            "Epoch 5/25\n",
            "13/13 [==============================] - 3s 217ms/step - loss: 0.1883 - accuracy: 0.9377 - val_loss: 0.1655 - val_accuracy: 0.9667\n",
            "Epoch 6/25\n",
            "13/13 [==============================] - 3s 200ms/step - loss: 0.1528 - accuracy: 0.9457 - val_loss: 0.0928 - val_accuracy: 0.9667\n",
            "Epoch 7/25\n",
            "13/13 [==============================] - 3s 218ms/step - loss: 0.1335 - accuracy: 0.9549 - val_loss: 0.0735 - val_accuracy: 0.9722\n",
            "Epoch 8/25\n",
            "13/13 [==============================] - 3s 221ms/step - loss: 0.1146 - accuracy: 0.9630 - val_loss: 0.0582 - val_accuracy: 0.9778\n",
            "Epoch 9/25\n",
            "13/13 [==============================] - 3s 223ms/step - loss: 0.1116 - accuracy: 0.9667 - val_loss: 0.0526 - val_accuracy: 0.9889\n",
            "Epoch 10/25\n",
            "13/13 [==============================] - 3s 199ms/step - loss: 0.1884 - accuracy: 0.9426 - val_loss: 0.1252 - val_accuracy: 0.9778\n",
            "Epoch 11/25\n",
            "13/13 [==============================] - 3s 197ms/step - loss: 0.1156 - accuracy: 0.9623 - val_loss: 0.2416 - val_accuracy: 0.9667\n",
            "Epoch 12/25\n",
            "13/13 [==============================] - 3s 198ms/step - loss: 0.1097 - accuracy: 0.9648 - val_loss: 0.1014 - val_accuracy: 0.9778\n",
            "Epoch 13/25\n",
            "13/13 [==============================] - 3s 218ms/step - loss: 0.0926 - accuracy: 0.9741 - val_loss: 0.0373 - val_accuracy: 0.9944\n",
            "Epoch 14/25\n",
            "13/13 [==============================] - 3s 198ms/step - loss: 0.0784 - accuracy: 0.9759 - val_loss: 0.1188 - val_accuracy: 0.9556\n",
            "Epoch 15/25\n",
            "13/13 [==============================] - 3s 202ms/step - loss: 0.0927 - accuracy: 0.9716 - val_loss: 0.0367 - val_accuracy: 0.9944\n",
            "Epoch 16/25\n",
            "13/13 [==============================] - 3s 199ms/step - loss: 0.0795 - accuracy: 0.9778 - val_loss: 0.0524 - val_accuracy: 0.9889\n",
            "Epoch 17/25\n",
            "13/13 [==============================] - 3s 197ms/step - loss: 0.0723 - accuracy: 0.9790 - val_loss: 0.0603 - val_accuracy: 0.9722\n",
            "Epoch 18/25\n",
            "13/13 [==============================] - 3s 197ms/step - loss: 0.0661 - accuracy: 0.9809 - val_loss: 0.0391 - val_accuracy: 0.9944\n",
            "Epoch 19/25\n",
            "13/13 [==============================] - 3s 197ms/step - loss: 0.0612 - accuracy: 0.9815 - val_loss: 0.0442 - val_accuracy: 0.9889\n",
            "Epoch 20/25\n",
            "13/13 [==============================] - 3s 199ms/step - loss: 0.0549 - accuracy: 0.9852 - val_loss: 0.0318 - val_accuracy: 0.9944\n",
            "Epoch 21/25\n",
            "13/13 [==============================] - 3s 197ms/step - loss: 0.0429 - accuracy: 0.9883 - val_loss: 0.0530 - val_accuracy: 0.9778\n",
            "Epoch 22/25\n",
            "13/13 [==============================] - 3s 198ms/step - loss: 0.1884 - accuracy: 0.9451 - val_loss: 0.0757 - val_accuracy: 0.9667\n",
            "Epoch 23/25\n",
            "13/13 [==============================] - 3s 197ms/step - loss: 0.1584 - accuracy: 0.9506 - val_loss: 0.0854 - val_accuracy: 0.9722\n",
            "Epoch 24/25\n",
            "13/13 [==============================] - 3s 198ms/step - loss: 0.1109 - accuracy: 0.9667 - val_loss: 0.0924 - val_accuracy: 0.9833\n",
            "Epoch 25/25\n",
            "13/13 [==============================] - 3s 198ms/step - loss: 0.0738 - accuracy: 0.9790 - val_loss: 0.0348 - val_accuracy: 0.9944\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WS1hLqXWsf6P"
      },
      "source": [
        "Accuracy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6srb6igksf6Q",
        "outputId": "dda5e25c-7b35-48ef-f614-d61db2fe55cb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "print(model.evaluate(valid_ds))"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "6/6 [==============================] - 0s 19ms/step - loss: 0.0384 - accuracy: 0.9944\n",
            "[0.03841450437903404, 0.9944444298744202]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yh4p9k18sf6R",
        "outputId": "6a45cc3a-79d6-4068-fe06-333299fd6d0d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "print(valid_ds)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<MapDataset shapes: ((None, 16000, 1), (None,)), types: (tf.float32, tf.int32)>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UTBuzXbM2ePX"
      },
      "source": [
        "model.save('model.h5')"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OgiFXaDf2JrM",
        "outputId": "a1dce90e-62ea-4ed8-a736-4b3eb618946f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "model = tf.keras.models.load_model('model.h5')\n",
        "model.layers[0].input_shape "
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(None, 16000, 1)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0gWhw-Ozsf6T"
      },
      "source": [
        "Predict"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SlLeX7jRsf6U",
        "outputId": "aef35408-ef28-4cf5-ecbf-087c643280a4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "SAMPLES_TO_DISPLAY = 10\n",
        "\n",
        "test_ds = paths_and_labels_to_dataset(valid_audio_paths, valid_labels)\n",
        "test_ds = test_ds.shuffle(buffer_size=BATCH_SIZE * 8, seed=SHUFFLE_SEED).batch(\n",
        "    BATCH_SIZE\n",
        ")\n",
        "\n",
        "test_ds = test_ds.map(lambda x, y: (add_noise(x, noises, scale=SCALE), y))\n",
        "\n",
        "print(test_ds)\n",
        "print(valid_ds)\n",
        "\n",
        "for audios, labels in test_ds.take(1):\n",
        "    # Get the signal FFT\n",
        "    ffts = audio_to_fft(audios)\n",
        "    # Predict\n",
        "    y_pred = model.predict(audios)\n",
        "    # Take random samples\n",
        "    rnd = np.random.randint(0, BATCH_SIZE, SAMPLES_TO_DISPLAY)\n",
        "    audios = audios.numpy()[rnd, :, :]\n",
        "    labels = labels.numpy()[rnd]\n",
        "    y_pred = np.argmax(y_pred, axis=-1)[rnd]\n",
        "\n",
        "    for index in range(SAMPLES_TO_DISPLAY):\n",
        "        # For every sample, print the true and predicted label\n",
        "        # as well as run the voice with the noise\n",
        "        # print(model.evaluate(test_ds)[1])\n",
        "        print(\n",
        "            \"Speaker:\\33{} {}\\33[0m\\tPredicted:\\33{} {}\\33[0m\".format(\n",
        "                \"[92m\" if labels[index] == y_pred[index] else \"[91m\",\n",
        "                class_names[labels[index]],\n",
        "                \"[92m\" if labels[index] == y_pred[index] else \"[91m\",\n",
        "                class_names[y_pred[index]],\n",
        "            )\n",
        "        )\n",
        "        if labels[index] ==y_pred[index]:\n",
        "            print(model.evaluate(test_ds)[1])\n",
        "            print(y_pred[index])\n",
        "            print(\"Welcome\")\n",
        "        else:\n",
        "            print(\"Sorry\")\n",
        "        # print(\"The speaker is\" if labels[index] == y_pred[index] else \"\", class_names[y_pred[index]])"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<MapDataset shapes: ((None, 16000, 1), (None,)), types: (tf.float32, tf.int32)>\n",
            "<MapDataset shapes: ((None, 16000, 1), (None,)), types: (tf.float32, tf.int32)>\n",
            "Speaker:\u001b[92m Nelson_Mandela\u001b[0m\tPredicted:\u001b[92m Nelson_Mandela\u001b[0m\n",
            "2/2 [==============================] - 0s 63ms/step - loss: 0.0400 - accuracy: 0.9889\n",
            "0.9888888597488403\n",
            "0\n",
            "Welcome\n",
            "Speaker:\u001b[92m harshit\u001b[0m\tPredicted:\u001b[92m harshit\u001b[0m\n",
            "2/2 [==============================] - 0s 20ms/step - loss: 0.0983 - accuracy: 0.9833\n",
            "0.9833333492279053\n",
            "1\n",
            "Welcome\n",
            "Speaker:\u001b[92m harshit\u001b[0m\tPredicted:\u001b[92m harshit\u001b[0m\n",
            "2/2 [==============================] - 0s 20ms/step - loss: 0.0345 - accuracy: 0.9944\n",
            "0.9944444298744202\n",
            "1\n",
            "Welcome\n",
            "Speaker:\u001b[92m Nelson_Mandela\u001b[0m\tPredicted:\u001b[92m Nelson_Mandela\u001b[0m\n",
            "2/2 [==============================] - 0s 19ms/step - loss: 0.0336 - accuracy: 0.9944\n",
            "0.9944444298744202\n",
            "0\n",
            "Welcome\n",
            "Speaker:\u001b[92m avish\u001b[0m\tPredicted:\u001b[92m avish\u001b[0m\n",
            "2/2 [==============================] - 0s 21ms/step - loss: 0.0376 - accuracy: 0.9944\n",
            "0.9944444298744202\n",
            "2\n",
            "Welcome\n",
            "Speaker:\u001b[92m harshit\u001b[0m\tPredicted:\u001b[92m harshit\u001b[0m\n",
            "2/2 [==============================] - 0s 19ms/step - loss: 0.0373 - accuracy: 0.9944\n",
            "0.9944444298744202\n",
            "1\n",
            "Welcome\n",
            "Speaker:\u001b[92m Nelson_Mandela\u001b[0m\tPredicted:\u001b[92m Nelson_Mandela\u001b[0m\n",
            "2/2 [==============================] - 0s 20ms/step - loss: 0.0352 - accuracy: 0.9944\n",
            "0.9944444298744202\n",
            "0\n",
            "Welcome\n",
            "Speaker:\u001b[92m harshit\u001b[0m\tPredicted:\u001b[92m harshit\u001b[0m\n",
            "2/2 [==============================] - 0s 20ms/step - loss: 0.0355 - accuracy: 0.9944\n",
            "0.9944444298744202\n",
            "1\n",
            "Welcome\n",
            "Speaker:\u001b[92m Nelson_Mandela\u001b[0m\tPredicted:\u001b[92m Nelson_Mandela\u001b[0m\n",
            "2/2 [==============================] - 0s 19ms/step - loss: 0.0534 - accuracy: 0.9833\n",
            "0.9833333492279053\n",
            "0\n",
            "Welcome\n",
            "Speaker:\u001b[92m Nelson_Mandela\u001b[0m\tPredicted:\u001b[92m Nelson_Mandela\u001b[0m\n",
            "2/2 [==============================] - 0s 19ms/step - loss: 0.0369 - accuracy: 0.9944\n",
            "0.9944444298744202\n",
            "0\n",
            "Welcome\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xkbpCGxGsf6X"
      },
      "source": [
        "#Predcit the speaker from the test dataset for real time pred. "
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4FQhwopPsf6a",
        "outputId": "a475e24d-a730-4eac-d220-cb473a7ca2ec",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "def predict(path, labels):\n",
        "\tp_ds = paths_and_labels_to_dataset(path, labels)\n",
        "\tp_ds = p_ds.shuffle(buffer_size=BATCH_SIZE * 8, seed=SHUFFLE_SEED).batch(\n",
        "    \tBATCH_SIZE\n",
        "\t)\n",
        "\n",
        "\n",
        "\tp_ds = p_ds.map(lambda x, y: (add_noise(x, noises, scale=SCALE), y))\n",
        "\n",
        "\tprint(p_ds)\n",
        "\t# print(valid_ds)\n",
        "\n",
        "\tfor audios, labels in p_ds.take(1):\n",
        "\t\t# Get the signal FFT\n",
        "\t\tffts = audio_to_fft(audios)\n",
        "\t\t# Predict\n",
        "\t\ty_pred = model.predict(audios)\n",
        "\t\t# Take random samples\n",
        "\t\trnd = np.random.randint(0, 1, 1)\n",
        "\t\taudios = audios.numpy()[rnd, :]\n",
        "\t\tlabels = labels.numpy()[rnd]\n",
        "\t\ty_pred = np.argmax(y_pred, axis=-1)[rnd]\n",
        "\n",
        "\t\tfor index in range(1):\n",
        "\t\t\t# For every sample, print the true and predicted label\n",
        "\t\t\t# as well as run the voice with the noise\n",
        "\t\t\tprint(\n",
        "\t\t\t\t\"Speaker:\\33{} {}\\33[0m\\tPredicted:\\33{} {}\\33[0m\".format(\n",
        "\t\t\t\t\t\"[92m\",y_pred[index],\n",
        "\t\t\t\t\t\"[92m\", y_pred[index]\n",
        "\t\t\t\t)\n",
        "\t\t\t)\n",
        "\t\t\t# print(model.evaluate(valid_ds)[1])\n",
        "\t\t\t# print(a[1])\n",
        "\t\t\tif class_names[y_pred[index]] == \"harshit\":\n",
        "\t\t\t\t# print(model.evaluate(p_ds)[1])\n",
        "\t\t\t\t\t# print(model.evaluate(valid_ds,verbose=0)[1])\n",
        "\t\t\t\tprint(\"Welcome\")\n",
        "\t\t\telse:\n",
        "\t\t\t\tprint(\"Sorry\")\n",
        "\t\t\tprint(class_names[y_pred[index]])\n",
        "\t\t\t# display(Audio(audios[index, :, :].squeeze(), rate=SAMPLING_RATE))\n",
        "\n",
        "path = [\"/content/244.wav\"]\n",
        "print(path)\n",
        "labels = [\"unknown\"]\n",
        "\n",
        "# path_ds = tf.data.Dataset.from_tensor_slices(audio_paths)\n",
        "# audio_ds = path_ds.map(lambda x: path_to_audio(x))\n",
        "# label_ds = tf.data.Dataset.from_tensor_slices(labels)\n",
        "# return tf.data.Dataset.zip((audio_ds, label_ds))\n",
        "\n",
        "predict(path, labels)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['/content/244.wav']\n",
            "<MapDataset shapes: ((None, 16000, 1), (None,)), types: (tf.float32, tf.string)>\n",
            "Speaker:\u001b[92m 1\u001b[0m\tPredicted:\u001b[92m 1\u001b[0m\n",
            "Welcome\n",
            "harshit\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ln92LaUat4DR"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}